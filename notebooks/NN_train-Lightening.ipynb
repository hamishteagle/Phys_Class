{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "sys.argv = [\"foo\",\"-r\",\"mini\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Driver\n",
    "from Driver import logging\n",
    "msg=logging.getLogger(\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NN_driver\n",
    "NN_driver.load_NN_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = NN_driver.num_workers\n",
    "batch_size = NN_driver.batch_size\n",
    "split_fraction = NN_driver.split_fraction\n",
    "epochs = NN_driver.epochs\n",
    "lr = NN_driver.lr\n",
    "weight_decay=NN_driver.weight_decay\n",
    "class_names=NN_driver.class_names\n",
    "num_classes = len(NN_driver.class_names)\n",
    "doReWeight=NN_driver.doReWeight\n",
    "doWeighted=NN_driver.doWeighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 58672), started 0:02:34 ago. (Use '!kill 58672' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9a5da8c8febc8d65\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9a5da8c8febc8d65\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightening_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DatasetLoader :: INFO     ::       Attempt to load:/nfs/dust/atlas/user/hteagle/PyAnalysisUtils/ML/NN/data/processed/data_Wh_21_2_112_reco_sig.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "lightning    :: INFO     ::       GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "lightning    :: INFO     ::       TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "lightning    :: INFO     ::       CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type         | Params\n",
      "-----------------------------------------------\n",
      "0 | dropout10     | AlphaDropout | 0     \n",
      "1 | dropout20     | AlphaDropout | 0     \n",
      "2 | dropout30     | AlphaDropout | 0     \n",
      "3 | linear_input  | Linear       | 5 K   \n",
      "4 | linear1       | Linear       | 19 K  \n",
      "5 | linear2       | Linear       | 19 K  \n",
      "6 | linear3       | Linear       | 19 K  \n",
      "7 | linear4       | Linear       | 19 K  \n",
      "8 | linear5       | Linear       | 19 K  \n",
      "9 | linear_output | Linear       | 705   \n",
      "lightning    :: INFO     ::       \n",
      "  | Name          | Type         | Params\n",
      "-----------------------------------------------\n",
      "0 | dropout10     | AlphaDropout | 0     \n",
      "1 | dropout20     | AlphaDropout | 0     \n",
      "2 | dropout30     | AlphaDropout | 0     \n",
      "3 | linear_input  | Linear       | 5 K   \n",
      "4 | linear1       | Linear       | 19 K  \n",
      "5 | linear2       | Linear       | 19 K  \n",
      "6 | linear3       | Linear       | 19 K  \n",
      "7 | linear4       | Linear       | 19 K  \n",
      "8 | linear5       | Linear       | 19 K  \n",
      "9 | linear_output | Linear       | 705   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  80%|███████▉  | 43/54 [01:44<00:26,  2.42s/it, loss=1.496, v_num=15]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 44/54 [01:46<00:24,  2.43s/it, loss=1.496, v_num=15]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../modules.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)## When training/calculating losses using CrossEntropyLoss we should feed it raw logits, it applies softmax itself. When applying/getting probabilites, we should switch this on..annoying\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating:  18%|█▊        | 2/11 [00:04<00:22,  2.48s/it]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 46/54 [01:51<00:19,  2.42s/it, loss=1.496, v_num=15]\n",
      "Validating:  36%|███▋      | 4/11 [00:09<00:16,  2.40s/it]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 48/54 [01:56<00:14,  2.42s/it, loss=1.496, v_num=15]\n",
      "Validating:  55%|█████▍    | 6/11 [00:14<00:11,  2.37s/it]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 50/54 [02:00<00:09,  2.41s/it, loss=1.496, v_num=15]\n",
      "Validating:  73%|███████▎  | 8/11 [00:18<00:07,  2.35s/it]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 52/54 [02:05<00:04,  2.41s/it, loss=1.496, v_num=15]\n",
      "Validating:  91%|█████████ | 10/11 [00:23<00:02,  2.37s/it]\u001b[A\n",
      "Epoch 1: 100%|██████████| 54/54 [02:09<00:00,  2.39s/it, loss=1.496, v_num=15]\n",
      "Epoch 2:  80%|███████▉  | 43/54 [01:43<00:26,  2.41s/it, loss=0.716, v_num=15]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 44/54 [01:46<00:24,  2.42s/it, loss=0.716, v_num=15]\n",
      "Validating:  18%|█▊        | 2/11 [00:04<00:21,  2.41s/it]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 46/54 [01:50<00:19,  2.41s/it, loss=0.716, v_num=15]\n",
      "Validating:  36%|███▋      | 4/11 [00:09<00:17,  2.44s/it]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 48/54 [01:55<00:14,  2.41s/it, loss=0.716, v_num=15]\n",
      "Validating:  55%|█████▍    | 6/11 [00:14<00:12,  2.43s/it]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 50/54 [02:00<00:09,  2.41s/it, loss=0.716, v_num=15]\n",
      "Validating:  73%|███████▎  | 8/11 [00:19<00:07,  2.41s/it]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 52/54 [02:05<00:04,  2.41s/it, loss=0.716, v_num=15]\n",
      "Validating:  91%|█████████ | 10/11 [00:23<00:02,  2.37s/it]\u001b[A\n",
      "Epoch 2: 100%|██████████| 54/54 [02:09<00:00,  2.39s/it, loss=0.716, v_num=15]\n",
      "Epoch 2: 100%|██████████| 54/54 [02:09<00:00,  2.39s/it, loss=0.716, v_num=15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "import modules\n",
    "model = modules.CatL(num_classes = num_classes, learning_rate=lr, batch_size=batch_size, weight_decay=weight_decay, split_fraction=split_fraction)\n",
    "trainer = Trainer(gpus=1, max_epochs = 2, num_sanity_val_steps=0)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/dust/atlas/user/hteagle/PyAnalysisUtils/ML/NN/notebooks/lightning_logs/version_15/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger_path = trainer.logger.save_dir+\"/\"+trainer.logger.name+\"/version_\"+str(trainer.logger.version)+\"/\"\n",
    "logger_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model back in its notmal format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DatasetLoader :: INFO     ::       Attempt to load:/nfs/dust/atlas/user/hteagle/PyAnalysisUtils/ML/NN/data/processed/data_Wh_21_2_112_reco_sig.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cat(\n",
       "  (dropout10): AlphaDropout(p=0.1, inplace=False)\n",
       "  (dropout20): AlphaDropout(p=0.2, inplace=False)\n",
       "  (dropout30): AlphaDropout(p=0.3, inplace=False)\n",
       "  (linear_input): Linear(in_features=35, out_features=140, bias=True)\n",
       "  (linear1): Linear(in_features=140, out_features=140, bias=True)\n",
       "  (linear2): Linear(in_features=140, out_features=140, bias=True)\n",
       "  (linear3): Linear(in_features=140, out_features=140, bias=True)\n",
       "  (linear4): Linear(in_features=140, out_features=140, bias=True)\n",
       "  (linear5): Linear(in_features=140, out_features=140, bias=True)\n",
       "  (linear_output): Linear(in_features=140, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), logger_path+\"model.pt\")\n",
    "from dataset import bbMeT_NN\n",
    "dataset = bbMeT_NN(root='data', device=\"cpu\", transform=None)\n",
    "ptmodel = modules.Cat(X_size=len(dataset.X_data[0]),num_classes=num_classes)\n",
    "ptmodel.load_state_dict(torch.load(logger_path+\"model.pt\"))\n",
    "ptmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New output:/nfs/dust/atlas/user/hteagle/PyAnalysisUtils/ML/NN/notebooks/lightning_logs/version_15/\n",
      "Got Pytorch model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../modules.py:64: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(x)## When training/calculating losses using CrossEntropyLoss we should feed it raw logits, it applies softmax itself. When applying/getting probabilites, we should switch this on..annoying\n"
     ]
    }
   ],
   "source": [
    "import XGB_board\n",
    "import importlib\n",
    "importlib.reload(XGB_board)\n",
    "board = XGB_board.board_object(ptmodel, xmini=dataset.X_data[0], device=\"cpu\", output_dir=logger_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DatasetLoader :: INFO     ::       Attempt to load:/nfs/dust/atlas/user/hteagle/PyAnalysisUtils/ML/NN/data/processed/data_Wh_21_2_112_reco_sig.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Load in one big batch using the splits from the model\n",
    "dataset = bbMeT_NN(root='data', device=\"cpu\", transform=None)\n",
    "train_loader = DataLoader(dataset, batch_size=len(model.train_indices))\n",
    "test_loader = DataLoader(dataset, batch_size=len(model.test_indices))\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pytorch_board :: INFO     ::       Getting input lists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/5 [05:07<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1063628it [00:27, 38709.17it/s]\n",
      "1063628it [00:25, 41050.71it/s]\n",
      "1063628it [00:26, 39608.01it/s]\n",
      "1063628it [00:27, 38045.44it/s]\n",
      "1063624it [00:46, 22917.49it/s]\n",
      "Pytorch_board :: INFO     ::       Finished getting test inputs\n"
     ]
    }
   ],
   "source": [
    "board.get_inputs(train_loader, test_loader)# Predict on the train and test datasets for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = board.draw_train_test_root()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "auc, curve = board.get_roc(class_ = \"Signal\")\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve.ax_.legend(\"Signal ROC, ACU: %f\"%(auc))\n",
    "curve.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
